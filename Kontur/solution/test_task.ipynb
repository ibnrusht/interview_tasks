{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cbbc8a",
   "metadata": {},
   "source": [
    "# 1. Data processing, Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "072ac43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "bb1e6e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e1b2d",
   "metadata": {},
   "source": [
    "Импорт файла в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8812deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>is_fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Москвичу Владимиру Клутину пришёл счёт за вмеш...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Агент Кокорина назвал езду по встречке житейск...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Госдума рассмотрит возможность введения секрет...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ФАС заблокировала поставку скоростных трамваев...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Против Навального завели дело о недоносительст...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  is_fake\n",
       "0  Москвичу Владимиру Клутину пришёл счёт за вмеш...        1\n",
       "1  Агент Кокорина назвал езду по встречке житейск...        0\n",
       "2  Госдума рассмотрит возможность введения секрет...        1\n",
       "3  ФАС заблокировала поставку скоростных трамваев...        0\n",
       "4  Против Навального завели дело о недоносительст...        1"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8935c32",
   "metadata": {},
   "source": [
    "Посмотрим на самые употребляемые слова в заголовках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c5d203c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "в         2486\n",
       "на        1244\n",
       "с          500\n",
       "и          494\n",
       "за         427\n",
       "по         381\n",
       "россии     378\n",
       "о          367\n",
       "для        314\n",
       "из         261\n",
       "dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.lower().str.split(expand=True).stack().value_counts().head(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a47dcfa",
   "metadata": {},
   "source": [
    "Видно, что топ возглавляют предлоги и союзы. Так как данные слова несут мало информации при использовании bag of words и являются частыми гостями в stop_words сборниках, плюс в дальнейшем я планирую использовать CountVectorizer(), который анализирует словесные единицы длиной от двух букв, имеет смысл убрать из заголовков эти слова, а затем снова рассмотреть топ наиболее употребляемых слов. Также в список слов, от которых следует избавиться, попадёт союз из-за, так как в CountVectorizer() он будет представлен в виде двух отдельных слов \"из\" и \"за\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "45b61fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "banned = ['в', 'с', 'и', 'о', 'к', 'у', 'за', 'по', 'из', 'для',\n",
    "          'от', 'не', 'из-за', 'на', 'до', 'об', 'во']\n",
    "\n",
    "f = lambda x: ' '.join([item for item in x.lower().split() if item not in banned])\n",
    "\n",
    "df['title'] = df['title'].apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "c9ebe2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "россии    378\n",
       "сша       153\n",
       "после      94\n",
       "рублей     94\n",
       "года       91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].str.split(expand=True).stack().value_counts().head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1813f3a4",
   "metadata": {},
   "source": [
    "Для начала следует использовать train_test_split с параметром random_state, чтобы случайным образом разделить базу для тренировки на две части. Попробуем посмотреть как себя поведёт naive bayes без стеммизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ced254e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "ea1c3985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82       562\n",
      "           1       0.82      0.87      0.84       590\n",
      "\n",
      "    accuracy                           0.83      1152\n",
      "   macro avg       0.84      0.83      0.83      1152\n",
      "weighted avg       0.84      0.83      0.83      1152\n",
      "\n",
      "0.8342013888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "clf = Pipeline([('cnv', CountVectorizer()),\n",
    "      ('tfidf', TfidfTransformer()),\n",
    "      ('nb', MultinomialNB())])\n",
    "\n",
    "clf.fit(X_train['title'], X_train['is_fake'])\n",
    "predicted = clf.predict(X_test['title'])\n",
    "print(classification_report(X_test['is_fake'], predicted))\n",
    "\n",
    "print(np.mean(X_test['is_fake'] == predicted))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3b0aa8a",
   "metadata": {},
   "source": [
    "Попробуем улучшить этот результат посредством варьирования параметров классификатора и кросс-валидации с помощью GridSearchCV. В данном случае, варьируемые параметры можно разделить на три части: 1) n-граммы, словесные единицы на которые CountVectorizer() разделяет текст, (1,1) - токеном считаются единичные слова, (1,2) - токенами считаются как единичные слова, так и пары слов; 2) использование idf - информативные слова могут несколько раз попадаться в длинных заголовках, что может привести к ошибочной классификации, использование параметра idf позволяет различать частоту использования тех или иных слов с учётом длины текста, 3) alpha - коэффициент laplas/lidstone smoothing для того чтобы обрабатывать слова, которые не встречались в датасете для тренировки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fcbfc405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters_nb = {'cnv__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'tfidf__use_idf': (True, False),\n",
    "                 'nb__alpha': (1.0, 1e-1, 1e-2, 1e-3, 0),\n",
    "                 }\n",
    "\n",
    "gs = GridSearchCV(clf, parameters_nb, scoring=\"accuracy\", n_jobs=-1, cv=5, verbose=10,\n",
    "                     return_train_score=True)\n",
    "\n",
    "gs = gs.fit(df[\"title\"], df[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "0aa9b24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8417862788396564"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c94f58c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_cnv__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_nb__alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.841786</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.840225</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.839702</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838661</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837271</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score param_cnv__ngram_range param_tfidf__use_idf  \\\n",
       "13         0.841786                 (1, 2)                False   \n",
       "12         0.840225                 (1, 2)                 True   \n",
       "3          0.839702                 (1, 1)                False   \n",
       "2          0.838661                 (1, 1)                 True   \n",
       "0          0.837271                 (1, 1)                 True   \n",
       "\n",
       "   param_nb__alpha  \n",
       "13             0.1  \n",
       "12             0.1  \n",
       "3              0.1  \n",
       "2              0.1  \n",
       "0              1.0  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)[[\"mean_test_score\",\n",
    "                                 \"param_cnv__ngram_range\",\n",
    "                                 \"param_tfidf__use_idf\",\n",
    "                                 \"param_nb__alpha\"]].sort_values(by=[\"mean_test_score\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0690a17",
   "metadata": {},
   "source": [
    "# 2. SVM"
   ]
  },
  {
   "cell_type": "raw",
   "id": "12521007",
   "metadata": {},
   "source": [
    "Попробуем использовать SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "0f39419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf_svm = Pipeline([('cnv', CountVectorizer()),\n",
    "      ('tfidf', TfidfTransformer()),\n",
    "      ('svm', SGDClassifier())])\n",
    "\n",
    "parameters_svm = {'cnv__ngram_range': [(1, 1),(1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'svm__alpha': (1e-4, 1e-5, 1e-6),\n",
    "                  'svm__class_weight': (None, 'balanced')\n",
    "                  }\n",
    "\n",
    "gs_svm = GridSearchCV(clf_svm, parameters_svm, scoring=\"accuracy\", n_jobs=-1, cv=5, verbose=10,\n",
    "                      return_train_score=True)\n",
    "gs_svm = gs_svm.fit(df[\"title\"], df[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e0c63c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350137863210735"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "358e5aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_cnv__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_svm__alpha</th>\n",
       "      <th>param_svm__class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.835014</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.834841</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.830844</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.830149</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.829109</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score param_cnv__ngram_range param_tfidf__use_idf  \\\n",
       "12         0.835014                 (1, 2)                 True   \n",
       "14         0.834841                 (1, 2)                 True   \n",
       "18         0.830844                 (1, 2)                 True   \n",
       "16         0.830149                 (1, 2)                 True   \n",
       "2          0.829109                 (1, 1)                 True   \n",
       "\n",
       "   param_svm__alpha param_svm__class_weight  \n",
       "12           0.0001                    None  \n",
       "14           0.0001                balanced  \n",
       "18          0.00001                balanced  \n",
       "16          0.00001                    None  \n",
       "2            0.0001                balanced  "
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_svm.cv_results_)[[\"mean_test_score\",\n",
    "                                 \"param_cnv__ngram_range\",\n",
    "                                 \"param_tfidf__use_idf\",\n",
    "                                 \"param_svm__alpha\",\n",
    "                                 \"param_svm__class_weight\"]].sort_values(by=[\"mean_test_score\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41b2b62e",
   "metadata": {},
   "source": [
    "Судя по всему, использование support-vector machine не приводит к улучшению результата."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19fe9f6",
   "metadata": {},
   "source": [
    "# 3. Stemming"
   ]
  },
  {
   "cell_type": "raw",
   "id": "876370d4",
   "metadata": {},
   "source": [
    "Попробуем применить стемминг к корпусу заголовков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "248e5df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "df['stemmed'] = df['title'].apply(lambda x: [stemmer.stem(y) for y in x.split()])\n",
    "df['stemmed'] = df['stemmed'].apply(lambda x: \" \".join([i for i in x]))\n",
    "\n",
    "parameters_nb = {'cnv__ngram_range': [(1,1), (1, 2), (2,2)],\n",
    "                 'tfidf__use_idf': ([True, False]),\n",
    "                 'nb__alpha': (2, 1, 0.1, 0.01,0.001),\n",
    "                 }\n",
    "\n",
    "gs_stemmed = GridSearchCV(clf, parameters_nb, scoring=\"accuracy\", n_jobs=-1, cv=5, verbose=10,\n",
    "                     return_train_score=True)\n",
    "\n",
    "gs_stemmed = gs_stemmed.fit(df[\"stemmed\"], df[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "315394db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8511645972101555"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_stemmed.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9a581aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_cnv__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_nb__alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.851165</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.851164</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.850990</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.850990</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.848907</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score param_cnv__ngram_range param_tfidf__use_idf  \\\n",
       "15         0.851165                 (1, 2)                False   \n",
       "2          0.851164                 (1, 1)                 True   \n",
       "5          0.850990                 (1, 1)                False   \n",
       "12         0.850990                 (1, 2)                 True   \n",
       "14         0.848907                 (1, 2)                 True   \n",
       "\n",
       "   param_nb__alpha  \n",
       "15             0.1  \n",
       "2                1  \n",
       "5              0.1  \n",
       "12               1  \n",
       "14             0.1  "
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_stemmed.cv_results_)[[\"mean_test_score\",\n",
    "                                 \"param_cnv__ngram_range\",\n",
    "                                 \"param_tfidf__use_idf\",\n",
    "                                 \"param_nb__alpha\"]].sort_values(by=[\"mean_test_score\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbec6fa5",
   "metadata": {},
   "source": [
    "Судя по всему, более точный подбор параметра alpha (от 1 до 0.1) поможет улучшить предсказательную способность модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "cd217e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "parameters_nb = {'cnv__ngram_range': [(1,1), (1, 2), (2,2)],\n",
    "                 'tfidf__use_idf': ([True, False]),\n",
    "                 'nb__alpha': (1, 0.8, 0.6, 0.4, 0.2, 0.1),\n",
    "                 }\n",
    "\n",
    "gs_stemmed = GridSearchCV(clf, parameters_nb, scoring=\"accuracy\", n_jobs=-1, cv=5, verbose=10,\n",
    "                     return_train_score=True)\n",
    "\n",
    "gs_stemmed = gs_stemmed.fit(df[\"stemmed\"], df[\"is_fake\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "bb30705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8532479305434887"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_stemmed.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "410c04ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_cnv__ngram_range</th>\n",
       "      <th>param_tfidf__use_idf</th>\n",
       "      <th>param_nb__alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.853248</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.853247</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.852207</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>False</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.852205</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.852033</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>True</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score param_cnv__ngram_range param_tfidf__use_idf  \\\n",
       "16         0.853248                 (1, 2)                 True   \n",
       "19         0.853247                 (1, 2)                False   \n",
       "21         0.852207                 (1, 2)                False   \n",
       "14         0.852205                 (1, 2)                 True   \n",
       "20         0.852033                 (1, 2)                 True   \n",
       "\n",
       "   param_nb__alpha  \n",
       "16             0.6  \n",
       "19             0.4  \n",
       "21             0.2  \n",
       "14             0.8  \n",
       "20             0.2  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs_stemmed.cv_results_)[[\"mean_test_score\",\n",
    "                                 \"param_cnv__ngram_range\",\n",
    "                                 \"param_tfidf__use_idf\",\n",
    "                                 \"param_nb__alpha\"]].sort_values(by=[\"mean_test_score\"], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ca55d",
   "metadata": {},
   "source": [
    "# 4. Финальная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f75e332",
   "metadata": {},
   "source": [
    "1. Удалить предлоги и союзы.\n",
    "2. Стемминг. Для эффективного стемминга, необходимо убрать некоторые знаки пунктуации.\n",
    "3. CountVectorizer(ngram_range=(1,2))\n",
    "Tfidftransformer(use_idf=True)\n",
    "MultinomialNB(alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61976d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cnv',\n",
       "                 CountVectorizer(ngram_range=(1, 2),\n",
       "                                 preprocessor=<function stemming at 0x0000019A43E20DC0>)),\n",
       "                ('tfidf', TfidfTransformer(use_idf=False)),\n",
       "                ('nb', MultinomialNB(alpha=0.4))])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "# removing unnecessary characters and stemming\n",
    "def stemming(string: str):\n",
    "    stop_words = ['в', 'с', 'и', 'о', 'к', 'у', 'за', 'по', 'из', 'для',\n",
    "                  'от', 'не', 'из-за', 'на', 'до', 'об', 'во']\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    text = re.sub('[^A-Za-z0-9 а-яА-я+:]+', '', string.lower())\n",
    "    text = [item for item in text.split() if item not in stop_words]\n",
    "    text = [stemmer.stem(y) for y in text]\n",
    "    text = ' '.join([i for i in text])\n",
    "    return text\n",
    "\n",
    "df = pd.read_csv(\"dataset/train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# creating train and test datasets\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# training classifier\n",
    "clf = Pipeline([('cnv', CountVectorizer(preprocessor=stemming, ngram_range=(1,2))),\n",
    "      ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "      ('nb', MultinomialNB(alpha=0.4))])\n",
    "clf.fit(X_train['title'], X_train['is_fake'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e04e0a5",
   "metadata": {},
   "source": [
    "Посмотрим на f1-метрику для тестовой части тренировочного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdaeb382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.85       562\n",
      "           1       0.86      0.87      0.86       590\n",
      "\n",
      "    accuracy                           0.86      1152\n",
      "   macro avg       0.86      0.86      0.86      1152\n",
      "weighted avg       0.86      0.86      0.86      1152\n",
      "\n",
      "0.859375\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_test['title'])\n",
    "print(classification_report(X_test['is_fake'], predicted))\n",
    "print(np.mean(X_test['is_fake'] == predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8687ce8",
   "metadata": {},
   "source": [
    "# 5. Обработка test.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0178df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(df['title'],df['is_fake'])\n",
    "\n",
    "test = pd.read_csv(\"dataset/test.tsv\", sep='\\t')\n",
    "predicted = clf.predict(test['title'])\n",
    "test['is_fake'] = predicted\n",
    "\n",
    "test.to_csv(\"predictions.tsv\", index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560ae32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
